import os
import pandas as pd
from sqlalchemy import create_engine, text
from lightfm import LightFM
from lightfm.data import Dataset
import numpy as np
from datetime import datetime
from collections import defaultdict

from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# DB ì—°ê²° URL ìƒì„±
DB_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# 1. DB ì—°ê²° (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì •ë³´ ì½ê¸°)
DB_URL = f"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}"
engine = create_engine(DB_URL)

# 2. ë°ì´í„° ë¡œë”©
print("ğŸ“¥ ì‚¬ìš©ì, ë¸Œëœë“œ, interaction ë°ì´í„° ë¡œë”© ì¤‘...")

with engine.connect() as conn:
    # ìœ ì € ì •ë³´
    user_df = pd.DataFrame(conn.execute(text(
        "SELECT id, gender, age_range FROM users"
    )).fetchall(), columns=["user_id", "gender", "age_range"])

    # ì˜¨ë³´ë”© ì •ë³´
    onboarding_df = pd.DataFrame(conn.execute(text(
        """
        SELECT user_id, brand_id, data_type
        FROM recommendation_base_data
        """
    )).fetchall(), columns=["user_id", "brand_id", "data_type"])

    # ë¸Œëœë“œ & ì¹´í…Œê³ ë¦¬ ì •ë³´
    brand_df = pd.DataFrame(conn.execute(text(
        "SELECT id, brand_name, category_id FROM brands"
    )).fetchall(), columns=["brand_id", "brand_name", "category_id"])

    # í–‰ë™ ë¡œê·¸ ì •ë³´
    interaction_df = pd.DataFrame(conn.execute(text(
        """
        SELECT al.user_id, b.id, al.action_type
        FROM action_logs al
        JOIN store s ON al.store_id = s.id
        JOIN brands b ON s.brand_id = b.id
        WHERE al.action_type IN ('MARKER_CLICK', 'FILTER_USED')
        """
    )).fetchall(), columns=["user_id", "brand_id", "action_type"])

    # ì¦ê²¨ì°¾ê¸° ëª©ë¡ ì •ë³´

# 4. ì˜¨ë³´ë”© ê¸°ë°˜ user_feature êµ¬ì„±
user_feature_map = defaultdict(list)

for user_id, group in onboarding_df.groupby("user_id"):
    recent = group[group["data_type"] == "RECENT"]["brand_id"].tolist()[:6]
    interest = group[group["data_type"] == "INTEREST"]["brand_id"].tolist()[:4]

    # ë¸Œëœë“œ ì•„ì´ë””ì— prefixë¥¼ ë¶™ì—¬ì„œ featureë¡œ ë§Œë“¦
    features = [f"recent_{b}" for b in recent] + [f"interest_{b}" for b in interest]
    user_feature_map[user_id] = features

# 5. LightFM ì…ë ¥ êµ¬ì„±
dataset = Dataset()
dataset.fit(users=user_df["user_id"], items=brand_df["brand_id"])

# ì „ì²´ ìœ ì € feature ì§‘í•©
all_user_features = set(f for feats in user_feature_map.values() for f in feats)
dataset.fit_partial(user_features=all_user_features)


print("ğŸ§¾ ì‚¬ìš©ìë³„ interaction êµ¬ì„± ì¤‘...")

# Action logê°€ ìˆëŠ” ìœ ì €ì™€ ì—†ëŠ” ìœ ì € ë¶„ë¦¬
users_with_logs = set(interaction_df["user_id"])
all_users = set(user_df["user_id"])
users_without_logs = all_users - users_with_logs

# ì‹¤ì œ interactionì€ action_logs ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±
real_interactions = list(zip(interaction_df["user_id"], interaction_df["brand_id"]))

# action logê°€ ì—†ëŠ” ìœ ì €ëŠ” ì²« ë¸Œëœë“œë§Œ ëŒ€ìƒìœ¼ë¡œ dummy interaction ìƒì„±
dummy_interactions = [(user_id, brand_df["brand_id"].iloc[0]) for user_id in users_without_logs]

combined_interactions = real_interactions + dummy_interactions

interactions, _ = dataset.build_interactions(combined_interactions)

user_features = dataset.build_user_features(
    [(uid, feats) for uid, feats in user_feature_map.items()]
)

# ëª¨ë¸ í•™ìŠµ
print("ğŸ§  LightFM ëª¨ë¸ í•™ìŠµ ì¤‘...")
model = LightFM(loss="warp")
model.fit(interactions, user_features=user_features, epochs=10, num_threads=2)

# 6. ì¶”ì²œ ìƒì„±
print("ğŸ“Š ì‚¬ìš©ìë³„ ì¶”ì²œ ìƒì„± ì¤‘...")

all_item_ids = brand_df["brand_id"].tolist()
recommendations = []

for user_id in user_df["user_id"]:
#     scores = model.predict(
#         user_ids=[user_df[user_df["user_id"] == user_id].index[0]],
#         item_ids=np.arange(len(all_item_ids)),
#         user_features=user_features
#     )
    user_index = user_df[user_df["user_id"] == user_id].index[0]
    user_id_array = np.full(len(all_item_ids), user_index)

    scores = model.predict(
        user_ids=user_id_array,
        item_ids=np.arange(len(all_item_ids)),
        user_features=user_features
    )

    top_k_indices = np.argsort(-scores)[:5]
    top_k = [(all_item_ids[i], scores[i]) for i in top_k_indices]

    for rank, (brand_id, score) in enumerate(top_k, start=1):
        recommendations.append({
            "user_id": user_id,
            "brand_id": brand_id,
            "score": float(score),
            "rank": rank,
            "created_at": datetime.utcnow()
        })

recommend_df = pd.DataFrame(recommendations)

# 7. ì¶”ì²œ ê²°ê³¼ CSVë¡œ ì €ì¥
print("ğŸ’¾ ì¶”ì²œ ê²°ê³¼ CSV ì €ì¥ ì¤‘...")

csv_path = "recommendations.csv"
recommend_df.to_csv(csv_path, index=False)

print(f"âœ… ì¶”ì²œ ì™„ë£Œ ë° CSV ì €ì¥ ì™„ë£Œ: {csv_path}")

# 7. ì¶”ì²œ ê²°ê³¼ ì €ì¥ (SQLAlchemy Core ì‚¬ìš©)
print("ğŸ’¾ ì¶”ì²œ ê²°ê³¼ DB ì €ì¥ ì¤‘...")

with engine.begin() as conn:
    for _, row in recommend_df.iterrows():
        conn.execute(text("""
            INSERT INTO recommendation (user_id, brand_id, score, rank, created_at)
            VALUES (:user_id, :brand_id, :score, :rank, :created_at)
        """), {
            "user_id": int(row.user_id),
            "brand_id": int(row.brand_id),
            "score": float(row.score),
            "rank": int(row['rank']),
            "created_at": row.created_at
        })

print("âœ… ì¶”ì²œ ì™„ë£Œ ë° DB ì €ì¥ ì™„ë£Œ.")