import os
import pandas as pd
from sqlalchemy import create_engine, text
from lightfm import LightFM
from lightfm.data import Dataset
import numpy as np
from datetime import datetime
from collections import defaultdict

from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_NAME = os.getenv("DB_NAME")

# DB ì—°ê²° URL ìƒì„±
DB_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# 1. DB ì—°ê²° (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì •ë³´ ì½ê¸°)
DB_URL = f"postgresql://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}"
engine = create_engine(DB_URL)

# 2. ë°ì´í„° ë¡œë”©
print("ğŸ“¥ ì‚¬ìš©ì, ë¸Œëœë“œ, ìƒí˜¸ì‘ìš© ë°ì´í„° ë¡œë”© ì¤‘...")

with engine.connect() as conn:
    # ìœ ì € ì •ë³´
    user_df = pd.DataFrame(conn.execute(text(
        "SELECT id, gender, age_range FROM users"
    )).fetchall(), columns=["user_id", "gender", "age_range"])

    # ì˜¨ë³´ë”© ì •ë³´
    onboarding_df = pd.DataFrame(conn.execute(text(
        """
        SELECT user_id, brand_id, data_type
        FROM recommendation_base_data
        """
    )).fetchall(), columns=["user_id", "brand_id", "data_type"])

    # ë¸Œëœë“œ & ì¹´í…Œê³ ë¦¬ ì •ë³´
    brand_df = pd.DataFrame(conn.execute(text(
        "SELECT id, brand_name, category_id FROM brands"
    )).fetchall(), columns=["brand_id", "brand_name", "category_id"])

    # í–‰ë™ ë¡œê·¸ ì •ë³´
    interaction_df = pd.DataFrame(conn.execute(text(
        """
        SELECT al.user_id, b.brand_id, al.action_type
        FROM action_logs al
        JOIN stores s ON al.store_id = s.id
        JOIN brands b ON s.brand_id = b.brand_id
        WHERE al.action_type IN ('marker_click', 'favorite')
        """
    )).fetchall(), columns=["user_id", "brand_id", "action_type"])

    # ì¦ê²¨ì°¾ê¸° ëª©ë¡

    #

# 4. ì˜¨ë³´ë”© ê¸°ë°˜ user_feature êµ¬ì„±
user_feature_map = defaultdict(list)

for user_id, group in onboarding_df.groupby("user_id"):
    recent = group[group["data_type"] == "RECENT"]["brand_id"].tolist()[:6]
    interest = group[group["data_type"] == "INTEREST"]["brand_id"].tolist()[:4]

    # ë¸Œëœë“œ ì•„ì´ë””ì— prefixë¥¼ ë¶™ì—¬ì„œ featureë¡œ ë§Œë“¦
    features = [f"recent_{b}" for b in recent] + [f"interest_{b}" for b in interest]
    user_feature_map[user_id] = features

# 5. LightFM ì…ë ¥ êµ¬ì„±
dataset = Dataset()
dataset.fit(users=user_df["user_id"], items=brand_df["brand_id"])

# ì „ì²´ ìœ ì € feature ì§‘í•©
all_user_features = set(f for feats in user_feature_map.values() for f in feats)
dataset.fit_partial(user_features=all_user_features)

(interactions, weights) = dataset.build_interactions([
    (row["user_id"], row["brand_id"], row["weight"])
    for _, row in interaction_df.iterrows()
])

user_features = dataset.build_user_features(
    [(uid, feats) for uid, feats in user_feature_map.items()]
)


# 5. ëª¨ë¸ í•™ìŠµ
print("ğŸ§  LightFM ëª¨ë¸ í•™ìŠµ ì¤‘...")
model = LightFM(loss="warp")
model.fit(interactions, user_features=user_features, sample_weight=weights, epochs=10, num_threads=2)

# 6. ì¶”ì²œ ìƒì„±
print("ğŸ“Š ì‚¬ìš©ìë³„ ì¶”ì²œ ìƒì„± ì¤‘...")

all_item_ids = brand_df["brand_id"].tolist()
recommendations = []

for user_id in user_df["user_id"]:
    known = interaction_df[interaction_df["user_id"] == user_id]["brand_id"].tolist()

    scores = model.predict(user_ids=user_id, item_ids=np.array(all_item_ids))
    scores = [(item_id, s) for item_id, s in zip(all_item_ids, scores) if item_id not in known]
    top_k = sorted(scores, key=lambda x: -x[1])[:5]

    for rank, (brand_id, score) in enumerate(top_k, start=1):
        recommendations.append({
            "user_id": user_id,
            "brand_id": brand_id,
            "score": float(score),
            "rank": rank,
            "created_at": datetime.utcnow()
        })

recommend_df = pd.DataFrame(recommendations)

# 7. ì¶”ì²œ ê²°ê³¼ CSVë¡œ ì €ì¥
print("ğŸ’¾ ì¶”ì²œ ê²°ê³¼ CSV ì €ì¥ ì¤‘...")

csv_path = "recommendations.csv"
recommend_df.to_csv(csv_path, index=False)

print(f"âœ… ì¶”ì²œ ì™„ë£Œ ë° CSV ì €ì¥ ì™„ë£Œ: {csv_path}")


# 7. ì¶”ì²œ ê²°ê³¼ ì €ì¥ (SQLAlchemy Core ì‚¬ìš©)
# print("ğŸ’¾ ì¶”ì²œ ê²°ê³¼ DB ì €ì¥ ì¤‘...")
#
# with engine.begin() as conn:
#     user_ids = recommend_df["user_id"].unique().tolist()
#
#     # í•´ë‹¹ ì‚¬ìš©ìë“¤ì˜ ê¸°ì¡´ ì¶”ì²œ ì‚­ì œ
#     conn.execute(text(
#         "DELETE FROM recommendation WHERE user_id = ANY(:uids)"
#     ), {"uids": user_ids})
#
#     # ì‚½ì… ë°˜ë³µ
#     for _, row in recommend_df.iterrows():
#         conn.execute(text("""
#             INSERT INTO recommendation (user_id, brand_id, score, rank, created_at)
#             VALUES (:user_id, :brand_id, :score, :rank, :created_at)
#         """), {
#             "user_id": int(row.user_id),
#             "brand_id": int(row.brand_id),
#             "score": float(row.score),
#             "rank": int(row.rank),
#             "created_at": row.created_at
#         })
#
# print("âœ… ì¶”ì²œ ì™„ë£Œ ë° DB ì €ì¥ ì™„ë£Œ.")